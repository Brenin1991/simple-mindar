
<html>
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <script src="https://aframe.io/releases/1.6.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.5/dist/mindar-image-aframe.prod.js"></script>
    <style>
      body {
        margin: 0;
        padding: 0;
        overflow: hidden;
      }
    </style>
  </head>
  <body>
    <a-scene 
      mindar-image="imageTargetSrc: ./targets.mind;" 
      color-space="sRGB" 
      renderer="colorManagement: true, physicallyCorrectLights" 
      vr-mode-ui="enabled: false" 
      device-orientation-permission-ui="enabled: false"
      id="ar-scene">
      <a-assets>
        <img id="card" src="https://cdn.jsdelivr.net/gh/hiukim/mind-ar-js@1.2.5/examples/image-tracking/assets/card-example/card.png" />
        <a-asset-item id="avatarModel" src="https://cdn.jsdelivr.net/gh/hiukim/mind-ar-js@1.2.5/examples/image-tracking/assets/card-example/softmind/scene.gltf"></a-asset-item>
      </a-assets>

      <a-camera position="0 0 0" look-controls="enabled: false"></a-camera>
      <a-entity mindar-image-target="targetIndex: 0" id="target-entity">
        <a-plane id="drawing-plane" position="0 0 0" height="0.552" width="1" rotation="0 0 0" material="transparent: true; opacity: 0"></a-plane>
        <a-gltf-model rotation="0 0 0 " position="0 0 0.1" scale="0.005 0.005 0.005" src="#avatarModel" animation="property: position; to: 0 0.1 0.1; dur: 1000; easing: easeInOutQuad; loop: true; dir: alternate">
      </a-entity>
    </a-scene>

    <script>
      // Sistema de captura e processamento de imagem do target
      let videoElement = null;
      let canvas = null;
      let ctx = null;
      let isTargetDetected = false;
      let textureCreated = false;

      // Aguarda o carregamento da cena
      const scene = document.querySelector('#ar-scene');
      const targetEntity = document.querySelector('#target-entity');
      const drawingPlane = document.querySelector('#drawing-plane');

      scene.addEventListener('renderstart', () => {
        // Obtém o elemento de vídeo da câmera do MindAR
        const mindarSystem = scene.systems['mindar-image-system'];
        if (mindarSystem && mindarSystem.video) {
          videoElement = mindarSystem.video;
          setupCanvas();
        }
      });

      // Configura o canvas para processamento de imagem
      function setupCanvas() {
        canvas = document.createElement('canvas');
        // Tamanho inicial, será ajustado dinamicamente
        canvas.width = 640;
        canvas.height = 480;
        ctx = canvas.getContext('2d');
        // Melhora a qualidade do processamento
        ctx.imageSmoothingEnabled = true;
        ctx.imageSmoothingQuality = 'high';
      }

      // Processa a imagem capturada com melhorias para desenhos preto e branco
      function processImage(imageData) {
        if (!canvas || !ctx) return null;

        // Ajusta o tamanho do canvas para corresponder ao vídeo
        if (imageData.videoWidth && imageData.videoHeight) {
          canvas.width = imageData.videoWidth;
          canvas.height = imageData.videoHeight;
        }

        // Desenha a imagem no canvas
        ctx.drawImage(imageData, 0, 0, canvas.width, canvas.height);
        
        // Obtém os dados da imagem
        const imageDataObj = ctx.getImageData(0, 0, canvas.width, canvas.height);
        const data = imageDataObj.data;

        // Processa a imagem para melhorar contraste e preparar para desenho
        // Converte para escala de cinza com pesos corretos
        for (let i = 0; i < data.length; i += 4) {
          const r = data[i];
          const g = data[i + 1];
          const b = data[i + 2];
          
          // Converte para escala de cinza usando pesos padrão
          const gray = 0.299 * r + 0.587 * g + 0.114 * b;
          
          // Aumenta contraste significativamente para destacar linhas pretas
          let contrast = ((gray / 255) - 0.5) * 2.0 + 0.5;
          contrast = Math.max(0, Math.min(1, contrast));
          
          // Aplica threshold para tornar mais preto e branco
          const threshold = 128;
          const adjusted = gray < threshold ? Math.max(0, gray * 0.7) : Math.min(255, gray * 1.3);
          
          // Inverte se necessário (dependendo do target - linhas pretas em fundo branco)
          // Se o desenho for preto em fundo branco, mantém assim
          // Se for branco em fundo preto, descomente a linha abaixo:
          // const final = 255 - adjusted;
          const final = adjusted;
          
          data[i] = final;     // R
          data[i + 1] = final; // G
          data[i + 2] = final; // B
          // Alpha permanece o mesmo
        }

        // Aplica o processamento de volta ao canvas
        ctx.putImageData(imageDataObj, 0, 0);
        
        // Aplica um filtro de suavização opcional
        ctx.filter = 'contrast(1.2) brightness(1.1)';
        ctx.drawImage(canvas, 0, 0);
        ctx.filter = 'none';
        
        return canvas.toDataURL('image/png');
      }

      // Aplica a textura no plano
      function applyTextureToPlane(imageUrl) {
        if (textureCreated) return; // Evita recriar múltiplas vezes
        
        const planeEl = drawingPlane;
        const mesh = planeEl.getObject3D('mesh');
        
        if (!mesh) {
          // Aguarda o mesh ser criado
          setTimeout(() => applyTextureToPlane(imageUrl), 100);
          return;
        }
        
        // Cria uma imagem a partir da data URL
        const img = new Image();
        img.onload = () => {
          // Cria textura a partir da imagem
          const texture = new THREE.Texture(img);
          texture.flipY = false; // Importante para AR
          texture.needsUpdate = true;
          
          if (mesh.material) {
            // Se já existe material, atualiza
            if (mesh.material.map) {
              mesh.material.map.dispose();
            }
            mesh.material.map = texture;
            mesh.material.needsUpdate = true;
            mesh.material.transparent = true;
            mesh.material.opacity = 1;
          } else {
            // Cria novo material
            mesh.material = new THREE.MeshBasicMaterial({
              map: texture,
              transparent: true,
              opacity: 1
            });
          }
          
          textureCreated = true;
          console.log('Textura aplicada com sucesso!');
        };
        img.onerror = (error) => {
          console.error('Erro ao carregar imagem:', error);
        };
        img.src = imageUrl;
      }

      // Captura frame quando target é detectado
      function captureTargetFrame() {
        if (!videoElement || !canvas || !ctx || textureCreated) return;

        try {
          // Processa a imagem do vídeo
          const imageUrl = processImage(videoElement);
          
          if (imageUrl) {
            applyTextureToPlane(imageUrl);
          }
        } catch (error) {
          console.error('Erro ao capturar frame:', error);
        }
      }

      // Escuta eventos do MindAR
      targetEntity.addEventListener('targetFound', () => {
        isTargetDetected = true;
        console.log('Target detectado! Capturando imagem...');
        
        // Aguarda um frame para garantir que a câmera está estável
        setTimeout(() => {
          captureTargetFrame();
        }, 500);
      });

      targetEntity.addEventListener('targetLost', () => {
        isTargetDetected = false;
        console.log('Target perdido');
      });

      // Alternativa: captura contínua enquanto target está visível
      setInterval(() => {
        if (isTargetDetected && !textureCreated && videoElement) {
          captureTargetFrame();
        }
      }, 1000);
    </script>
  </body>
</html>