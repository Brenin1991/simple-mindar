
<html>
  <head>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <script src="https://aframe.io/releases/1.6.0/aframe.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/mind-ar@1.2.5/dist/mindar-image-aframe.prod.js"></script>
    <!-- OpenCV.js para processamento de imagem e extra√ß√£o de regi√£o -->
    <script async src="https://docs.opencv.org/4.8.0/opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
    <style>
      body {
        margin: 0;
        padding: 0;
        overflow: hidden;
      }
    </style>
  </head>
  <body>
      <a-scene 
      mindar-image="imageTargetSrc: ./targets.mind;" 
      color-space="sRGB" 
      renderer="colorManagement: true, physicallyCorrectLights" 
      vr-mode-ui="enabled: false" 
      device-orientation-permission-ui="enabled: true"
      id="ar-scene">
      <a-assets>
        <img id="card" src="https://cdn.jsdelivr.net/gh/hiukim/mind-ar-js@1.2.5/examples/image-tracking/assets/card-example/card.png" />
      </a-assets>

      <a-camera position="0 0 0" look-controls="enabled: true; magicWindowTrackingEnabled: true"></a-camera>
      <a-entity mindar-image-target="targetIndex: 0" id="target-entity">
        <a-plane id="drawing-plane" position="0 0 0" height="1" width="1" rotation="0 0 0" material="transparent: true; opacity: 0"></a-plane>
      </a-entity>
    </a-scene>

    <script>
      // Sistema de captura e processamento de imagem do target
      let videoElement = null;
      let canvas = null;
      let ctx = null;
      let isTargetDetected = false;
      let textureCreated = false;
      let opencvReady = false;
      let mindarSystem = null;
      let lastCaptureTime = 0;
      let captureInterval = null;
      let planeFixed = false; // Indica se o plano j√° foi fixado na cena
      let fixedPosition = null; // Posi√ß√£o fixa do plano
      let fixedRotation = null; // Rota√ß√£o fixa do plano
      let fixedScale = null; // Escala fixa do plano
      let continuousCaptureEnabled = false; // Controla se deve continuar capturando
      let particlesCreated = false; // Indica se as part√≠culas j√° foram criadas
      let particles = []; // Array para armazenar as part√≠culas
      let particleUpdateLoop = null; // Loop de atualiza√ß√£o das part√≠culas
      const CAPTURE_UPDATE_INTERVAL = 5000; // Atualiza a textura a cada 5 segundos (aumentado de 2s)
      const PARTICLE_COUNT = 15; // N√∫mero de part√≠culas a criar

      // Aguarda o carregamento da cena
      const scene = document.querySelector('#ar-scene');
      const targetEntity = document.querySelector('#target-entity');
      const drawingPlane = document.querySelector('#drawing-plane');

      // Callback quando OpenCV est√° pronto
      function onOpenCvReady() {
        opencvReady = true;
        console.log('‚úÖ OpenCV.js carregado e pronto!');
      }

      // Fun√ß√£o para encontrar o elemento de v√≠deo (fallback)
      function findVideoElement() {
        // Tenta m√∫ltiplas formas de acessar o v√≠deo
        if (!mindarSystem) {
          mindarSystem = scene.systems['mindar-image-system'];
        }
        
        if (!mindarSystem) {
          console.log('MindAR System ainda n√£o dispon√≠vel');
        }
        
        if (mindarSystem) {
          // Tenta acessar o v√≠deo de diferentes formas
          if (mindarSystem.video) {
            videoElement = mindarSystem.video;
            console.log('V√≠deo encontrado via mindarSystem.video');
          } else if (mindarSystem.el && mindarSystem.el.video) {
            videoElement = mindarSystem.el.video;
            console.log('V√≠deo encontrado via mindarSystem.el.video');
          } else if (mindarSystem.videoEl) {
            videoElement = mindarSystem.videoEl;
            console.log('V√≠deo encontrado via mindarSystem.videoEl');
          } else if (mindarSystem.videoTexture) {
            // Algumas vers√µes do MindAR exp√µem o v√≠deo como textura
            const texture = mindarSystem.videoTexture;
            if (texture && texture.image) {
              videoElement = texture.image;
              console.log('V√≠deo encontrado via videoTexture.image');
            }
          }
          
          // Tenta acessar via el (elemento da cena)
          if (!videoElement && mindarSystem.el) {
            const el = mindarSystem.el;
            if (el.components && el.components['mindar-image-system']) {
              const comp = el.components['mindar-image-system'];
              if (comp.video) {
                videoElement = comp.video;
                console.log('V√≠deo encontrado via component.video');
              }
            }
          }
        }
        
        // Tenta encontrar o v√≠deo no DOM (√∫ltima tentativa)
        if (!videoElement) {
          // Procura por todos os v√≠deos no DOM
          const videos = document.querySelectorAll('video');
          console.log('V√≠deos encontrados no DOM:', videos.length);
          
          for (let video of videos) {
            console.log('Verificando v√≠deo:', {
              readyState: video.readyState,
              videoWidth: video.videoWidth,
              videoHeight: video.videoHeight,
              src: video.src || 'N/A',
              paused: video.paused
            });
            
            // Prefere v√≠deos que est√£o prontos e t√™m dimens√µes
            if (video.readyState >= 2 && video.videoWidth > 0) {
              videoElement = video;
              console.log('‚úÖ V√≠deo encontrado no DOM e pronto!');
              break;
            } else if (video.readyState > 0) {
              // Aceita v√≠deos que est√£o carregando mas ainda n√£o prontos
              videoElement = video;
              console.log('‚úÖ V√≠deo encontrado no DOM (carregando)...');
              
              // Aguarda o v√≠deo estar pronto
              video.addEventListener('loadeddata', () => {
                console.log('V√≠deo carregado completamente');
              }, { once: true });
              break;
            }
          }
        }
        
        // Tenta acessar via THREE.js renderer
        if (!videoElement && scene.renderer) {
          const renderer = scene.renderer;
          if (renderer.domElement) {
            const video = renderer.domElement.querySelector('video');
            if (video) {
              videoElement = video;
              console.log('V√≠deo encontrado via renderer.domElement');
            }
          }
        }
        
        if (videoElement) {
          console.log('‚úÖ V√≠deo configurado:', {
            readyState: videoElement.readyState,
            videoWidth: videoElement.videoWidth,
            videoHeight: videoElement.videoHeight,
            playing: !videoElement.paused,
            src: videoElement.src || 'N/A'
          });
          setupCanvas();
          return true;
        } else {
          console.warn('‚ö†Ô∏è V√≠deo n√£o encontrado, tentando novamente...');
          return false;
        }
      }

      // Aguarda o sistema MindAR estar pronto
      function waitForMindARSystem() {
        // Tenta acessar o sistema com diferentes nomes poss√≠veis
        const systemNames = ['mindar-image-system', 'mindarSystem', 'mindar'];
        let system = null;
        
        for (let name of systemNames) {
          system = scene.systems[name];
          if (system) {
            console.log(`‚úÖ Sistema MindAR encontrado como: ${name}`);
            break;
          }
        }
        
        if (system) {
          mindarSystem = system;
          
          // Aguarda o v√≠deo estar dispon√≠vel
          const checkVideo = () => {
            // Tenta m√∫ltiplas formas de acessar o v√≠deo
            if (system.video) {
              videoElement = system.video;
              console.log('‚úÖ V√≠deo encontrado via system.video');
              setupCanvas();
              return true;
            } else if (system.videoEl) {
              videoElement = system.videoEl;
              console.log('‚úÖ V√≠deo encontrado via system.videoEl');
              setupCanvas();
              return true;
            } else if (system.el && system.el.video) {
              videoElement = system.el.video;
              console.log('‚úÖ V√≠deo encontrado via system.el.video');
              setupCanvas();
              return true;
            }
            return false;
          };
          
          // Tenta encontrar o v√≠deo imediatamente
          if (!checkVideo()) {
            // Aguarda eventos do MindAR
            if (system.el) {
              system.el.addEventListener('arReady', () => {
                console.log('AR Ready!');
                checkVideo();
              });
            }
            
            // Tenta periodicamente
            const videoCheck = setInterval(() => {
              if (checkVideo()) {
                clearInterval(videoCheck);
              }
            }, 500);
            
            // Para ap√≥s 10 segundos
            setTimeout(() => clearInterval(videoCheck), 10000);
          }
          
          return true;
        }
        
        return false;
      }

      // Aguarda a cena estar pronta
      scene.addEventListener('renderstart', () => {
        console.log('Render iniciado, aguardando MindAR...');
        // Aguarda um pouco para o sistema inicializar
        setTimeout(() => {
          if (!waitForMindARSystem()) {
            // Se n√£o encontrou, tenta encontrar o v√≠deo no DOM
            findVideoElement();
          }
        }, 2000);
      });
      
      // Tenta encontrar periodicamente o sistema e o v√≠deo
      const systemCheckInterval = setInterval(() => {
        if (!videoElement) {
          // Primeiro tenta encontrar o sistema
          if (!mindarSystem) {
            waitForMindARSystem();
          }
          
          // Depois tenta encontrar o v√≠deo diretamente no DOM
          if (!videoElement) {
            const videos = document.querySelectorAll('video');
            if (videos.length > 0) {
              for (let video of videos) {
                if (video.readyState > 0) {
                  videoElement = video;
                  console.log('‚úÖ V√≠deo encontrado no DOM durante verifica√ß√£o peri√≥dica!');
                  setupCanvas();
                  clearInterval(systemCheckInterval);
                  return;
                }
              }
            }
          }
          
          // Se encontrou o v√≠deo, para a verifica√ß√£o
          if (videoElement) {
            clearInterval(systemCheckInterval);
          }
        } else {
          clearInterval(systemCheckInterval);
        }
      }, 1000);
      
      // Para a verifica√ß√£o ap√≥s 30 segundos
      setTimeout(() => {
        clearInterval(systemCheckInterval);
        if (!videoElement) {
          console.warn('‚ö†Ô∏è N√£o foi poss√≠vel encontrar o v√≠deo ap√≥s 30 segundos');
        }
      }, 30000);

      // Configura o canvas para processamento de imagem
      function setupCanvas() {
        canvas = document.createElement('canvas');
        // Tamanho inicial, ser√° ajustado dinamicamente
        canvas.width = 640;
        canvas.height = 480;
        ctx = canvas.getContext('2d');
        // Melhora a qualidade do processamento
        ctx.imageSmoothingEnabled = true;
        ctx.imageSmoothingQuality = 'high';
      }

      // Obt√©m as coordenadas do target usando o plano AR como refer√™ncia
      function getTargetCorners() {
        try {
          // Usa o plano AR que est√° alinhado com o target
          const planeMesh = drawingPlane.getObject3D('mesh');
          if (!planeMesh) {
            console.warn('Plano AR mesh n√£o encontrado');
            return null;
          }
          
          // Atualiza a matriz do mundo
          drawingPlane.object3D.updateMatrixWorld();
          
          // Se o plano j√° est√° fixo, sempre retorna as coordenadas (n√£o depende do tracking)
          if (planeFixed) {
            // Usa a posi√ß√£o fixa do plano
            console.log('Usando posi√ß√£o fixa do plano para captura');
          } else {
            // Verifica se o target est√° vis√≠vel (s√≥ quando ainda est√° usando tracking)
            const targetVisible = targetEntity.getAttribute('visible');
            if (targetVisible === false) {
              console.warn('Target entity n√£o est√° vis√≠vel');
              return null;
            }
          }
          
          // Obt√©m a matriz de transforma√ß√£o do plano
          const worldMatrix = new THREE.Matrix4();
          planeMesh.updateMatrixWorld();
          worldMatrix.copy(planeMesh.matrixWorld);
          
          // Dimens√µes do plano (quadrado)
          const planeWidth = 1.0;  // Largura do plano em metros
          const planeHeight = 1.0; // Altura do plano em metros (quadrado)
          const halfWidth = planeWidth / 2;
          const halfHeight = planeHeight / 2;
          
          // Cantos do plano no espa√ßo local
          const localCorners = [
            new THREE.Vector3(-halfWidth, halfHeight, 0),  // superior esquerdo
            new THREE.Vector3(halfWidth, halfHeight, 0),    // superior direito
            new THREE.Vector3(halfWidth, -halfHeight, 0),  // inferior direito
            new THREE.Vector3(-halfWidth, -halfHeight, 0)   // inferior esquerdo
          ];
          
          // Transforma para coordenadas do mundo
          const worldCorners = localCorners.map(corner => {
            const worldCorner = corner.clone();
            worldCorner.applyMatrix4(worldMatrix);
            return worldCorner;
          });
          
          console.log('Cantos do target no espa√ßo 3D:', worldCorners);
          return worldCorners;
          
        } catch (e) {
          console.warn('Erro ao obter coordenadas do target:', e);
        }
        
        return null;
      }

      // Converte coordenadas 3D para coordenadas 2D na tela
      function project3DTo2D(corners3D, videoWidth, videoHeight) {
        if (!corners3D) return null;
        
        // Usa a c√¢mera do A-Frame para projetar
        const camera = scene.camera;
        if (!camera) {
          console.warn('C√¢mera n√£o encontrada');
          return null;
        }
        
        const corners2D = corners3D.map((corner, index) => {
          const vector = new THREE.Vector3(corner.x, corner.y, corner.z);
          
          // Projeta o ponto 3D para coordenadas da c√¢mera
          vector.project(camera);
          
          // Converte de coordenadas normalizadas (-1 a 1) para pixels
          // A c√¢mera do A-Frame usa coordenadas onde (0,0) √© o centro
          const x = (vector.x * 0.5 + 0.5) * videoWidth;
          const y = (1 - (vector.y * 0.5 + 0.5)) * videoHeight; // Inverte Y
          
          // Garante que as coordenadas est√£o dentro dos limites
          const clampedX = Math.max(0, Math.min(videoWidth, x));
          const clampedY = Math.max(0, Math.min(videoHeight, y));
          
          console.log(`Canto ${index}: 3D(${corner.x.toFixed(2)}, ${corner.y.toFixed(2)}, ${corner.z.toFixed(2)}) -> 2D(${clampedX.toFixed(0)}, ${clampedY.toFixed(0)})`);
          
          return { x: clampedX, y: clampedY };
        });
        
        return corners2D;
      }

      // Extrai a regi√£o do target usando OpenCV (perspective transform)
      function extractTargetRegion(videoFrame, targetCorners2D) {
        if (!opencvReady) {
          console.warn('OpenCV ainda n√£o est√° pronto');
          return null;
        }
        
        try {
          const videoWidth = videoFrame.videoWidth || videoFrame.width;
          const videoHeight = videoFrame.videoHeight || videoFrame.height;
          
          console.log(`Extraindo regi√£o: ${videoWidth}x${videoHeight}`);
          console.log('Cantos:', targetCorners2D);
          
          // Cria um canvas tempor√°rio para o frame do v√≠deo
          const tempCanvas = document.createElement('canvas');
          tempCanvas.width = videoWidth;
          tempCanvas.height = videoHeight;
          const tempCtx = tempCanvas.getContext('2d');
          tempCtx.drawImage(videoFrame, 0, 0);
          
          // Converte para OpenCV Mat
          const src = cv.imread(tempCanvas);
          
          // Ordena os pontos corretamente (superior esquerdo, superior direito, inferior direito, inferior esquerdo)
          // Garante que os pontos est√£o na ordem correta
          const orderedCorners = [...targetCorners2D];
          
          // Define os pontos de origem (cantos do target na imagem)
          const srcPoints = cv.matFromArray(4, 1, cv.CV_32FC2, [
            orderedCorners[0].x, orderedCorners[0].y,
            orderedCorners[1].x, orderedCorners[1].y,
            orderedCorners[2].x, orderedCorners[2].y,
            orderedCorners[3].x, orderedCorners[3].y
          ]);
          
          // Define os pontos de destino (ret√¢ngulo retificado)
          const size = 512; // Tamanho da imagem extra√≠da
          const dstPoints = cv.matFromArray(4, 1, cv.CV_32FC2, [
            0, 0,
            size, 0,
            size, size,
            0, size
          ]);
          
          // Calcula a matriz de transforma√ß√£o perspectiva
          const M = cv.getPerspectiveTransform(srcPoints, dstPoints);
          
          // Aplica a transforma√ß√£o
          const dst = new cv.Mat();
          cv.warpPerspective(src, dst, M, new cv.Size(size, size));
          
          // Converte de volta para canvas
          cv.imshow(canvas, dst);
          
          // Limpa mem√≥ria
          src.delete();
          dst.delete();
          srcPoints.delete();
          dstPoints.delete();
          M.delete();
          
          console.log('‚úÖ Regi√£o extra√≠da com sucesso!');
          return canvas.toDataURL('image/png');
        } catch (error) {
          console.error('‚ùå Erro ao extrair regi√£o do target:', error);
          return null;
        }
      }

      // Extrai regi√£o usando detec√ß√£o autom√°tica de contornos (fallback)
      function extractTargetRegionAuto(videoFrame) {
        if (!opencvReady) {
          return null;
        }
        
        try {
          console.log('üîç Tentando detec√ß√£o autom√°tica de contornos...');
          const videoWidth = videoFrame.videoWidth || videoFrame.width;
          const videoHeight = videoFrame.videoHeight || videoFrame.height;
          
          const tempCanvas = document.createElement('canvas');
          tempCanvas.width = videoWidth;
          tempCanvas.height = videoHeight;
          const tempCtx = tempCanvas.getContext('2d');
          tempCtx.drawImage(videoFrame, 0, 0);
          
          const src = cv.imread(tempCanvas);
          const gray = new cv.Mat();
          cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);
          
          // Aplica threshold
          const thresh = new cv.Mat();
          cv.threshold(gray, thresh, 127, 255, cv.THRESH_BINARY);
          
          // Encontra contornos
          const contours = new cv.MatVector();
          const hierarchy = new cv.Mat();
          cv.findContours(thresh, contours, hierarchy, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE);
          
          // Encontra o maior contorno (provavelmente o target)
          let maxArea = 0;
          let maxContour = null;
          for (let i = 0; i < contours.size(); i++) {
            const contour = contours.get(i);
            const area = cv.contourArea(contour);
            if (area > maxArea && area > videoWidth * videoHeight * 0.1) {
              maxArea = area;
              maxContour = contour;
            }
          }
          
          if (maxContour) {
            // Aproxima o contorno para obter os cantos
            const epsilon = 0.02 * cv.arcLength(maxContour, true);
            const approx = new cv.Mat();
            cv.approxPolyDP(maxContour, approx, epsilon, true);
            
            if (approx.rows === 4) {
              // Temos 4 cantos!
              const corners = [];
              for (let i = 0; i < 4; i++) {
                corners.push({
                  x: approx.data32S[i * 2],
                  y: approx.data32S[i * 2 + 1]
                });
              }
              
              // Extrai usando os cantos encontrados
              const extracted = extractTargetRegion(videoFrame, corners);
              
              src.delete();
              gray.delete();
              thresh.delete();
              contours.delete();
              hierarchy.delete();
              approx.delete();
              
              return extracted;
            }
            
            approx.delete();
          }
          
          src.delete();
          gray.delete();
          thresh.delete();
          contours.delete();
          hierarchy.delete();
          
          return null;
        } catch (error) {
          console.error('Erro na detec√ß√£o autom√°tica:', error);
          return null;
        }
      }

      // Processa a imagem extra√≠da do target
      function processExtractedImage(imageData) {
        if (!canvas || !ctx) {
          console.error('Canvas n√£o configurado');
          return null;
        }

        try {
          // Ajusta o tamanho do canvas
          if (imageData.width && imageData.height) {
            canvas.width = imageData.width;
            canvas.height = imageData.height;
          }

          // Desenha a imagem no canvas
          ctx.drawImage(imageData, 0, 0, canvas.width, canvas.height);
        } catch (error) {
          console.error('Erro ao desenhar imagem no canvas:', error);
          return null;
        }
        
        // N√£o processa alpha aqui - o shader vai fazer isso
        // Apenas aplica ajustes leves de contraste/brilho se necess√°rio
        ctx.filter = 'contrast(1.1) brightness(1.05)';
        ctx.drawImage(canvas, 0, 0);
        ctx.filter = 'none';
        
        return canvas.toDataURL('image/png');
      }

      // Cria shader customizado que transforma branco em alpha
      function createWhiteToAlphaShader() {
        return {
          uniforms: {
            tDiffuse: { value: null },
            whiteThreshold: { value: 0.75 }, // Threshold mais baixo para pegar mais brancos
            alphaThreshold: { value: 0.1 },
            colorDiffThreshold: { value: 0.25 } // Diferen√ßa maior para pegar mais varia√ß√µes de branco/cinza
          },
          vertexShader: `
            varying vec2 vUv;
            void main() {
              vUv = uv;
              gl_Position = projectionMatrix * modelViewMatrix * vec4(position, 1.0);
            }
          `,
          fragmentShader: `
            uniform sampler2D tDiffuse;
            uniform float whiteThreshold;
            uniform float alphaThreshold;
            uniform float colorDiffThreshold;
            varying vec2 vUv;
            
            void main() {
              vec4 texColor = texture2D(tDiffuse, vUv);
              
              // Calcula o brilho do pixel
              float brightness = (texColor.r + texColor.g + texColor.b) / 3.0;
              
              // Verifica se √© branco/cinza claro (todos os canais altos e similares)
              // Cores pintadas ter√£o diferen√ßa entre os canais RGB
              float maxChannel = max(max(texColor.r, texColor.g), texColor.b);
              float minChannel = min(min(texColor.r, texColor.g), texColor.b);
              float channelDiff = maxChannel - minChannel;
              
              // Verifica se √© branco/cinza claro: brilho alto E canais similares
              bool isWhiteOrLightGray = (brightness >= whiteThreshold) && (channelDiff < colorDiffThreshold);
              
              // Verifica se √© uma cor pintada (tem diferen√ßa significativa entre canais)
              bool isColored = channelDiff > 0.15;
              
              float finalAlpha = 0.0;
              vec3 finalColor = texColor.rgb;
              
              if (isWhiteOrLightGray && !isColored) {
                // Branco/cinza claro = transparente (cutoff mais agressivo)
                finalAlpha = 0.0;
              } else if (isColored) {
                // Cores pintadas = totalmente opaco (mesmo que sejam claras)
                finalAlpha = 1.0;
              } else {
                // Linhas pretas/escuras = vis√≠vel com alpha baseado na escurid√£o
                float darkness = 1.0 - brightness;
                finalAlpha = max(alphaThreshold, darkness);
                // Escurece linhas pretas para melhor contraste
                if (brightness < 0.5) {
                  finalColor = finalColor * 0.8;
                }
              }
              
              gl_FragColor = vec4(finalColor, finalAlpha);
            }
          `
        };
      }

      // Fixa o plano na posi√ß√£o atual (desconecta do tracking)
      function fixPlanePosition() {
        if (planeFixed) return; // J√° est√° fixo
        
        const planeEl = drawingPlane;
        const planeObject3D = planeEl.object3D;
        
        // Atualiza a matriz do mundo para obter a posi√ß√£o correta
        planeObject3D.updateMatrixWorld();
        
        // Obt√©m a posi√ß√£o, rota√ß√£o e escala no espa√ßo do mundo
        const worldPosition = new THREE.Vector3();
        const worldRotation = new THREE.Euler();
        const worldQuaternion = new THREE.Quaternion();
        const worldScale = new THREE.Vector3();
        
        planeObject3D.matrixWorld.decompose(worldPosition, worldQuaternion, worldScale);
        worldRotation.setFromQuaternion(worldQuaternion);
        
        // Salva as transforma√ß√µes do mundo
        fixedPosition = worldPosition.clone();
        fixedRotation = worldRotation.clone();
        fixedScale = worldScale.clone();
        
        // Remove o plano do target entity e adiciona diretamente na cena
        const targetEntity3D = targetEntity.object3D;
        const scene3D = scene.object3D;
        
        // Remove do parent (target entity)
        targetEntity3D.remove(planeObject3D);
        
        // Adiciona diretamente na cena
        scene3D.add(planeObject3D);
        
        // Aplica a posi√ß√£o/rota√ß√£o/escala fixas (agora no espa√ßo da cena)
        planeObject3D.position.copy(fixedPosition);
        planeObject3D.rotation.copy(fixedRotation);
        planeObject3D.scale.copy(fixedScale);
        
        // Atualiza a matriz
        planeObject3D.updateMatrixWorld();
        
        // Garante que o plano est√° vis√≠vel
        planeEl.setAttribute('visible', true);
        planeEl.setAttribute('material', 'opacity', 1);
        
        planeFixed = true;
        console.log('üìå Plano fixado na cena! (n√£o segue mais o tracking)');
        console.log('Posi√ß√£o fixa (mundo):', fixedPosition);
        console.log('Rota√ß√£o fixa (mundo):', fixedRotation);
        console.log('Escala fixa (mundo):', fixedScale);
        console.log('Plano vis√≠vel:', planeEl.getAttribute('visible'));
      }

      // Aplica a textura no plano
      function applyTextureToPlane(imageUrl, forceUpdate = false) {
        if (textureCreated && !forceUpdate) return; // Evita recriar m√∫ltiplas vezes, a menos que forceUpdate seja true
        
        const planeEl = drawingPlane;
        const mesh = planeEl.getObject3D('mesh');
        
        if (!mesh) {
          // Aguarda o mesh ser criado
          setTimeout(() => applyTextureToPlane(imageUrl, forceUpdate), 100);
          return;
        }
        
        // Se √© a primeira captura, fixa o plano na posi√ß√£o atual
        if (!textureCreated && !planeFixed) {
          fixPlanePosition();
        }
        
        // Cria uma imagem a partir da data URL
        const img = new Image();
        img.onload = () => {
          // Cria textura a partir da imagem
          const texture = new THREE.Texture(img);
          texture.flipY = true; // Corrige a invers√£o vertical
          texture.needsUpdate = true;
          
          // Verifica se a textura est√° pronta
          if (!texture || !texture.image) {
            console.error('Textura n√£o est√° pronta');
            return;
          }
          
          // Cria o shader customizado que transforma branco em alpha
          const shaderMaterial = createWhiteToAlphaShader();
          shaderMaterial.uniforms.tDiffuse.value = texture;
          
          // Cria material com shader customizado
          const material = new THREE.ShaderMaterial({
            uniforms: shaderMaterial.uniforms,
            vertexShader: shaderMaterial.vertexShader,
            fragmentShader: shaderMaterial.fragmentShader,
            transparent: true,
            side: THREE.DoubleSide,
            depthWrite: false
          });
          
          if (mesh.material) {
            // Se j√° existe material, descarta o antigo
            if (mesh.material.map) {
              mesh.material.map.dispose();
            }
            if (mesh.material.dispose) {
              mesh.material.dispose();
            }
          }
          
          mesh.material = material;
          mesh.material.needsUpdate = true;
          
          // Torna o plano vis√≠vel
          planeEl.setAttribute('material', 'opacity', 1);
          
          textureCreated = true;
          console.log('‚úÖ Textura com shader WebGL aplicada! (branco ‚Üí alpha)');
          
          // Cria part√≠culas flutuantes ap√≥s a textura ser criada
          if (!particlesCreated) {
            createFloatingParticles(texture);
          }
        };
        img.onerror = (error) => {
          console.error('Erro ao carregar imagem:', error);
        };
        img.src = imageUrl;
      }

      // Cria part√≠culas flutuantes com a textura
      function createFloatingParticles(texture) {
        if (particlesCreated) return;
        
        console.log('‚ú® Criando part√≠culas flutuantes...');
        
        const shaderTemplate = createWhiteToAlphaShader();
        
        // Garante que a textura est√° atualizada
        if (texture && texture.image) {
          texture.needsUpdate = true;
          texture.flipY = true;
        }
        
        for (let i = 0; i < PARTICLE_COUNT; i++) {
          // Posi√ß√£o aleat√≥ria espalhada ao redor da c√¢mera
          const angle = (i / PARTICLE_COUNT) * Math.PI * 2; // Distribui em c√≠rculo
          const radius = 6 + Math.random() * 5; // Dist√¢ncia da c√¢mera
          const x = Math.cos(angle) * radius;
          const y = (Math.random() - 0.5) * 4; // Altura variada
          const z = -10 - Math.random() * 10; // Profundidade variada
          
          // Cria entidade A-Frame para a part√≠cula
          const particleEl = document.createElement('a-plane');
          particleEl.setAttribute('id', `particle-${i}`);
          particleEl.setAttribute('width', '0.4');
          particleEl.setAttribute('height', '0.4');
          particleEl.setAttribute('position', `${x} ${y} ${z}`);
          particleEl.setAttribute('material', {
            transparent: true,
            opacity: 1
          });
          // N√£o usa look-at do A-Frame para evitar distor√ß√£o
          // Vamos fazer isso manualmente via THREE.js
          
          // Anima√ß√£o de flutua√ß√£o
          const floatHeight = 0.3 + Math.random() * 0.3;
          const floatDuration = 2000 + Math.random() * 2000;
          particleEl.setAttribute('animation', {
            property: 'position',
            to: `${x} ${y + floatHeight} ${z}`,
            dur: floatDuration,
            easing: 'easeInOutSine',
            loop: true,
            dir: 'alternate'
          });
          
          // Rota√ß√£o suave (apenas em Z para n√£o distorcer)
          particleEl.setAttribute('animation__rotation', {
            property: 'rotation',
            to: `0 0 ${360}`,
            dur: 5000 + Math.random() * 5000,
            loop: true
          });
          
          // Adiciona √† cena
          scene.appendChild(particleEl);
          
          // Aguarda o mesh ser criado e aplica o shader
          setTimeout(() => {
            const mesh = particleEl.getObject3D('mesh');
            if (mesh) {
              // Garante que a escala est√° fixa para evitar distor√ß√£o
              mesh.scale.set(1, 1, 1);
              
              // Cria material com shader usando a mesma textura
              const particleMaterial = new THREE.ShaderMaterial({
                uniforms: {
                  tDiffuse: { value: texture },
                  whiteThreshold: { value: shaderTemplate.uniforms.whiteThreshold.value },
                  alphaThreshold: { value: shaderTemplate.uniforms.alphaThreshold.value },
                  colorDiffThreshold: { value: shaderTemplate.uniforms.colorDiffThreshold.value }
                },
                vertexShader: shaderTemplate.vertexShader,
                fragmentShader: shaderTemplate.fragmentShader,
                transparent: true,
                side: THREE.DoubleSide,
                depthWrite: false
              });
              
              if (mesh.material && mesh.material.dispose) {
                mesh.material.dispose();
              }
              
              mesh.material = particleMaterial;
              mesh.material.needsUpdate = true;
              
              // Armazena refer√™ncia do mesh
              particles.push({
                el: particleEl,
                mesh: mesh,
                baseY: y,
                baseZ: z
              });
              
              console.log(`‚úÖ Part√≠cula ${i} criada com shader`);
            }
          }, 100 + i * 50); // Delay escalonado para melhor performance
        }
        
        particlesCreated = true;
        console.log(`‚úÖ ${PARTICLE_COUNT} part√≠culas flutuantes criadas!`);
        
        // Inicia loop de atualiza√ß√£o para fazer part√≠culas olharem para a c√¢mera
        startParticleUpdateLoop();
      }

      // Loop de atualiza√ß√£o para fazer part√≠culas olharem para a c√¢mera (sem distorcer)
      function startParticleUpdateLoop() {
        if (particleUpdateLoop) return; // J√° est√° rodando
        
        const updateParticles = () => {
          const camera = scene.camera;
          if (!camera) {
            particleUpdateLoop = requestAnimationFrame(updateParticles);
            return;
          }
          
          // Obt√©m a posi√ß√£o da c√¢mera no mundo
          const cameraWorldPos = new THREE.Vector3();
          camera.getWorldPosition(cameraWorldPos);
          
          // Atualiza cada part√≠cula
          particles.forEach((particle) => {
            if (!particle.mesh || !particle.mesh.parent) return;
            
            // Obt√©m a rota√ß√£o Z atual da anima√ß√£o
            const currentRotZ = particle.el.getAttribute('rotation').z || 0;
            
            // Usa lookAt do THREE.js para olhar para a c√¢mera
            particle.mesh.lookAt(cameraWorldPos);
            
            // Garante que a escala est√° sempre fixa (1, 1, 1) - evita esticamento
            particle.mesh.scale.set(1, 1, 1);
            
            // Preserva a rota√ß√£o Z da anima√ß√£o
            particle.mesh.rotation.z = currentRotZ;
          });
          
          particleUpdateLoop = requestAnimationFrame(updateParticles);
        };
        
        updateParticles();
        console.log('üîÑ Loop de atualiza√ß√£o de part√≠culas iniciado');
      }

      // Atualiza a textura periodicamente para capturar o desenho pintado
      function startContinuousCapture() {
        if (captureInterval) {
          clearInterval(captureInterval);
        }
        
        // S√≥ inicia se estiver habilitado
        if (!continuousCaptureEnabled) {
          console.log('Captura cont√≠nua desabilitada');
          return;
        }
        
        captureInterval = setInterval(() => {
          // Se o plano j√° est√° fixo, usa a posi√ß√£o fixa para capturar
          // Se ainda n√£o est√° fixo, usa o tracking
          const planeMesh = drawingPlane.getObject3D('mesh');
          
          if (planeFixed) {
            // Plano j√° est√° fixo, captura usando a posi√ß√£o fixa
            if (planeMesh && videoElement && videoElement.readyState >= 2 && continuousCaptureEnabled) {
              const now = Date.now();
              if (now - lastCaptureTime >= CAPTURE_UPDATE_INTERVAL) {
                console.log('üîÑ Atualizando textura (plano fixo)...');
                lastCaptureTime = now;
                captureTargetFrame(true); // forceUpdate = true
              }
            }
          } else {
            // Ainda n√£o fixou, usa o tracking
            const targetVisible = targetEntity.getAttribute('visible');
            if (planeMesh && (isTargetDetected || targetVisible !== false) && videoElement && videoElement.readyState >= 2 && continuousCaptureEnabled) {
              const now = Date.now();
              if (now - lastCaptureTime >= CAPTURE_UPDATE_INTERVAL) {
                console.log('üîÑ Atualizando textura para capturar desenho pintado...');
                lastCaptureTime = now;
                captureTargetFrame(true); // forceUpdate = true
              }
            }
          }
        }, CAPTURE_UPDATE_INTERVAL);
      }

      function stopContinuousCapture() {
        if (captureInterval) {
          clearInterval(captureInterval);
          captureInterval = null;
        }
      }

      // Captura frame quando target √© detectado
      function captureTargetFrame(forceUpdate = false) {
        console.log('Tentando capturar frame...', {
          videoElement: !!videoElement,
          canvas: !!canvas,
          ctx: !!ctx,
          textureCreated: textureCreated,
          forceUpdate: forceUpdate,
          videoReady: videoElement && videoElement.readyState >= 2
        });
        
        if (!videoElement) {
          console.warn('V√≠deo n√£o dispon√≠vel, tentando encontrar...');
          findVideoElement();
          return;
        }
        
        if (!canvas || !ctx) {
          console.warn('Canvas n√£o configurado');
          setupCanvas();
          return;
        }
        
        // Se j√° criou a textura e n√£o √© uma atualiza√ß√£o for√ßada, n√£o captura novamente
        if (textureCreated && !forceUpdate) {
          console.log('Textura j√° foi criada (use forceUpdate=true para atualizar)');
          return;
        }
        
        // Verifica se o v√≠deo est√° pronto
        if (videoElement.readyState < 2) {
          console.warn('V√≠deo ainda n√£o est√° pronto, aguardando...');
          videoElement.addEventListener('loadeddata', () => {
            setTimeout(captureTargetFrame, 100);
          }, { once: true });
          return;
        }

        try {
          console.log('Processando imagem do v√≠deo...');
          
          // Tenta capturar do v√≠deo diretamente
          let imageSource = videoElement;
          
          // Se o v√≠deo n√£o estiver dispon√≠vel, tenta alternativas
          if (!imageSource || (imageSource.readyState !== undefined && imageSource.readyState < 2)) {
            console.warn('V√≠deo n√£o est√° pronto, tentando alternativas...');
            
            // Tenta usar o renderer WebGL para capturar
            const renderer = scene.renderer;
            if (renderer && renderer.domElement) {
              try {
                // Tenta ler do canvas WebGL
                const gl = renderer.getContext();
                if (gl) {
                  const width = renderer.domElement.width || 640;
                  const height = renderer.domElement.height || 480;
                  const pixels = new Uint8Array(width * height * 4);
                  gl.readPixels(0, 0, width, height, gl.RGBA, gl.UNSIGNED_BYTE, pixels);
                  
                  // Cria canvas tempor√°rio
                  const tempCanvas = document.createElement('canvas');
                  tempCanvas.width = width;
                  tempCanvas.height = height;
                  const tempCtx = tempCanvas.getContext('2d');
                  const imageData = tempCtx.createImageData(width, height);
                  
                  // Inverte verticalmente (WebGL tem origem no canto inferior esquerdo)
                  for (let y = 0; y < height; y++) {
                    for (let x = 0; x < width; x++) {
                      const srcIndex = ((height - 1 - y) * width + x) * 4;
                      const dstIndex = (y * width + x) * 4;
                      imageData.data[dstIndex] = pixels[srcIndex];
                      imageData.data[dstIndex + 1] = pixels[srcIndex + 1];
                      imageData.data[dstIndex + 2] = pixels[srcIndex + 2];
                      imageData.data[dstIndex + 3] = pixels[srcIndex + 3];
                    }
                  }
                  tempCtx.putImageData(imageData, 0, 0);
                  imageSource = tempCanvas;
                  console.log('‚úÖ Usando WebGL renderer como fonte');
                }
              } catch (e) {
                console.warn('Erro ao capturar do WebGL:', e);
              }
            }
          }
          
          if (!imageSource) {
            console.error('Nenhuma fonte de imagem dispon√≠vel');
            return;
          }
          
          // Tenta extrair apenas a regi√£o do target
          let imageUrl = null;
          
          if (opencvReady) {
            console.log('üîç Tentando extrair regi√£o do target com OpenCV...');
            
            // Obt√©m as coordenadas do target
            const corners3D = getTargetCorners();
            
            if (corners3D && imageSource.videoWidth) {
              console.log('‚úÖ Coordenadas 3D obtidas, projetando para 2D...');
              
              // Converte coordenadas 3D para 2D
              const corners2D = project3DTo2D(
                corners3D, 
                imageSource.videoWidth, 
                imageSource.videoHeight
              );
              
              if (corners2D && corners2D.length === 4) {
                console.log('‚úÖ Coordenadas 2D do target:', corners2D);
                
                // Valida se as coordenadas s√£o v√°lidas
                const valid = corners2D.every(c => 
                  c.x >= 0 && c.x <= imageSource.videoWidth && 
                  c.y >= 0 && c.y <= imageSource.videoHeight
                );
                
                if (valid) {
                  // Extrai a regi√£o do target
                  console.log('üìê Extraindo regi√£o do target...');
                  const extractedImageUrl = extractTargetRegion(imageSource, corners2D);
                  
                  if (extractedImageUrl) {
                    console.log('‚úÖ Regi√£o extra√≠da! Processando imagem...');
                    // Processa a imagem extra√≠da
                    const img = new Image();
                    img.onload = () => {
                      const processedUrl = processExtractedImage(img);
                      if (processedUrl) {
                        console.log('‚úÖ Regi√£o do target extra√≠da e processada!');
                        applyTextureToPlane(processedUrl, forceUpdate);
                        return; // Sucesso!
                      }
                    };
                    img.onerror = () => {
                      console.error('Erro ao carregar imagem extra√≠da');
                    };
                    img.src = extractedImageUrl;
                    return; // Sai da fun√ß√£o, o processamento continua no onload
                  } else {
                    console.error('‚ùå Falha ao extrair regi√£o do target');
                  }
                } else {
                  console.warn('‚ö†Ô∏è Coordenadas inv√°lidas, tentando detec√ß√£o autom√°tica...');
                  // Tenta detec√ß√£o autom√°tica de contornos
                  const autoExtracted = extractTargetRegionAuto(imageSource);
                  if (autoExtracted) {
                    const img = new Image();
                    img.onload = () => {
                      const processedUrl = processExtractedImage(img);
                      if (processedUrl) {
                        console.log('‚úÖ Regi√£o extra√≠da via detec√ß√£o autom√°tica!');
                        applyTextureToPlane(processedUrl, forceUpdate);
                        return;
                      }
                    };
                    img.src = autoExtracted;
                    return;
                  }
                }
              } else {
                console.warn('‚ö†Ô∏è N√£o foi poss√≠vel projetar coordenadas 3D para 2D');
              }
            } else {
              console.warn('‚ö†Ô∏è N√£o foi poss√≠vel obter coordenadas do target ou dimens√µes do v√≠deo');
            }
            
            console.warn('‚ö†Ô∏è N√£o foi poss√≠vel extrair regi√£o do target, usando imagem completa...');
          } else {
            console.warn('‚ö†Ô∏è OpenCV n√£o est√° pronto ainda');
          }
          
          // Fallback: processa a imagem completa se n√£o conseguir extrair a regi√£o
          console.log('üì∑ Processando imagem completa como fallback...');
          imageUrl = processExtractedImage(imageSource);
          
          if (imageUrl) {
            console.log('‚úÖ Imagem processada com sucesso, aplicando textura...');
            applyTextureToPlane(imageUrl, forceUpdate);
          } else {
            console.error('‚ùå Falha ao processar imagem');
          }
        } catch (error) {
          console.error('Erro ao capturar frame:', error);
          console.error('Stack:', error.stack);
        }
      }

      // Escuta eventos do MindAR
      targetEntity.addEventListener('targetFound', () => {
        isTargetDetected = true;
        console.log('=== TARGET DETECTADO ===');
        console.log('Estado:', {
          videoElement: !!videoElement,
          videoReady: videoElement ? videoElement.readyState : 'N/A',
          canvas: !!canvas,
          textureCreated: textureCreated,
          planeFixed: planeFixed
        });
        
        // Se o plano j√° est√° fixo, n√£o precisa fazer nada (j√° foi capturado)
        if (planeFixed) {
          console.log('Plano j√° est√° fixo, ignorando detec√ß√£o do target');
          return;
        }
        
        // Se o v√≠deo ainda n√£o foi encontrado, tenta encontrar agora
        if (!videoElement) {
          findVideoElement();
        }
        
        // Aguarda um pouco para garantir que a c√¢mera est√° est√°vel
        setTimeout(() => {
          // Primeira captura (desenho original) - isso vai fixar o plano
          captureTargetFrame(false);
          
          // Op√ß√£o: descomente a linha abaixo para habilitar captura cont√≠nua
          // Isso atualizar√° a textura periodicamente para capturar o desenho pintado
          // continuousCaptureEnabled = true;
          // startContinuousCapture();
          
          console.log('‚úÖ Captura inicial conclu√≠da. Para habilitar atualiza√ß√µes cont√≠nuas, descomente as linhas no c√≥digo.');
        }, 300);
      });

      targetEntity.addEventListener('targetLost', () => {
        console.log('‚ö†Ô∏è Target perdido pelo MindAR (pode ser porque foi pintado)');
        // N√£o marca como perdido imediatamente - tenta manter o tracking
        // O tracking cont√≠nuo vai tentar recapturar usando a posi√ß√£o do plano
        
        // Aguarda um pouco antes de parar completamente
        setTimeout(() => {
          // Se ainda n√£o detectou novamente, para a captura
          if (!isTargetDetected) {
            console.log('Target realmente perdido, parando captura');
            stopContinuousCapture();
          }
        }, 1000);
      });

      // Captura cont√≠nua enquanto target est√° vis√≠vel (com mais tentativas)
      setInterval(() => {
        if (isTargetDetected && !textureCreated) {
          if (!videoElement) {
            findVideoElement();
          }
          if (videoElement && videoElement.readyState >= 2) {
            captureTargetFrame();
          }
        }
      }, 500);
      
      // Log inicial
      console.log('Sistema de captura inicializado');
    </script>
  </body>
</html>